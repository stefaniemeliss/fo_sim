---
title: "FO Simulator - preliminary analysis"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output: html_document
---

For the analysis below, exclusion criteria for participants in the feedback orientation study were applied.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# libraries
library(kableExtra)
library(dplyr)
library(GGally)

# empty work space
rm(list = ls())

# get directories
dir <- getwd()

# process data: assumes this has been run
source("C:/Users/stefanie.meliss/OneDrive - Ambition Institute/code/colour_palette.R")
# source(file.path(dir_root, "1_prepare_pretest_data.R"))

# function to determine outliers
is_outlier_iqr <- function(x) {
  return(x < quantile(x, 0.25, na.rm = T) - 1.5 * IQR(x, na.rm = T) | x > quantile(x, 0.75, na.rm = T) + 1.5 * IQR(x, na.rm = T))
}

is_outlier_sd <- function(x) {
  return(x < mean(x, na.rm = T) - 3 * sd(x, na.rm = T) | x > mean(x, na.rm = T) + 3 * sd(x, na.rm = T))
}

# read in data
file = file.path(dir, "pretest_ARK.xlsx")
df <- xlsx::read.xlsx(file, sheetName = "SCALES")



```

## Descriptives and outlier identification

As a first step, all descriptives are computed for all variables measured. The sum score for each scale was computed following instructions given by the scale author(s). We have the same number of observations for each scale. To process n-back data, trial-level data was used (after removing practice trails). For each participant, event counts (n-back trial vs. non n-back trial) and performance according to signal detection theory (i.e., hits, misses, false alarms) were extracted. Additionally, rates for each event performance type were computed.  


```{r, echo = F, results='asis'}
# compute descriptives for all scales and nback data
first_col <- which(names(df) == "fo")
tmp <- psych::describe(df[, first_col:ncol(df)])

# round values
tmp <- round(tmp, 2)
# add scale name
tmp$vars <- row.names(tmp)

# print to markdown
kbl(tmp, caption = "Measurement descriptives", row.names = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))



```

Next, outliers are identified based on two criteria: (1) all values are considered outliers that are outside +/- 1.5 IQRs, or (2) all values outside +/- 3 SD from the mean. The results reveal that the IQR method is more sensitive to outliers.

```{r, echo = F, results='asis'}

# determien col names to check for outliers
scales <- names(df)[grep("fo|conscient|m_a|p_a|task_|pref", names(df))]
scales <- scales[!grepl("fo_", scales)]
scales <- c(scales, "rate_accuracy")

# for each scale, check for outliers
outlier_iqr <- df[, c("pseudonym", scales)]
outlier_sd <- df[, c("pseudonym", scales)]

# count number of outliers
outlier_iqr[, paste0(scales, "_outlier")] <- apply(df[scales], MARGIN = 2, is_outlier_iqr)
outlier_sd[, paste0(scales, "_outlier")] <- apply(df[scales], MARGIN = 2, is_outlier_sd) 

# combine to one table
tmp <- rbind(
  colSums(outlier_iqr[, grepl("outlier", names(outlier_iqr))], na.rm = T), #IQR
  colSums(outlier_sd[, grepl("outlier", names(outlier_sd))], na.rm = T) # SD
)
tmp <- as.data.frame(tmp)
row.names(tmp) <- c("outlier_iqr", "outlier_Sd")

# print to markdown
kbl(tmp, caption = "Outlier count", row.names = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

As a next step, the pseudonyms of participants with outlying values are identified:

```{r, echo = F, results='asis'}

for (scale in scales) {
  
  tmp <- outlier_iqr[outlier_iqr[, paste0(scale, "_outlier")] == T, c("pseudonym", scale)]
  tmp <- subset(tmp, !is.na(pseudonym))
  
  if (nrow(tmp) > 0) {
    print(kbl(tmp, caption = paste(scale), row.names = F) %>%
            kable_styling(bootstrap_options = c("striped", "hover", "condensed")))
    cat("\n")
  }
  
  
}

cat("**No nback data:", outlier_iqr$pseudonym[is.na(outlier_iqr[, paste0(scale, "_outlier")])], "**\n\n")

```

For the nback, additional checks were performed to identify ppt that have misunderstood the task. This was assumed if participants had a response rate (any key press) equal to 1 (n = 1) or equal to 0 (n = 5), if their hit rate was 0 (n = 7) or if the hit rate was smaller than the false alarm rate (n = 3). In total, 9 participants are identified based on these criteria. Of note, all of them have also been captured using the IQR outlier criteria.    

```{r, echo = F, results='asis'}
rates_nback <- names(df)[grep("rate_", names(df))]


# remove ppt that did not respond at all or responded in all trials or have a hitrate of 0
desc <- df[df$rate_response == 0 | df$rate_response == 1 | df$rate_hits == 0 | df$rate_hits < df$rate_fa, c("pseudonym", rates_nback)]
desc <- na.omit(desc)

kbl(desc, caption = "participants who likely misunderstood nback task", row.names = F) %>%
            kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```


# DISREGARD BELOW!

### Questionnaire data

The sum score for each scale was computed following instructions given by the scale author(s). We have the same number of observations for each scale.

```{r scales, echo = F, results='asis'}
scales <- names(df)[grep("fo|conscient|m_a|p_a|task_|pref", names(df))]

# compute descriptives for fo subscales
tmp <- psych::describe(df[, scales])
# round values
tmp <- round(tmp, 2)
# add scale name
tmp$vars <- row.names(tmp)

# print to markdown
kbl(tmp, caption = "Scale descriptives", row.names = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

To better understand how the data is distributed and whether scales correlate with each other, a scatterplot matrix with embedded histrograms is produced. The results suggests that FO does not correlate with any neighbouring constructs.  


```{r, echo=FALSE, results='asis', fig.align='center', fig.height=12, fig.width=12, message=F, warning=F}
# save data for matrix in seperate df
desc <- df[, c("pseudonym", scales)]

# define plotting function for lower diagonal
lowerfun <- function(data,mapping){
  ggplot(data = data, mapping = mapping)+
    geom_point(position=position_jitter(height=0.01, width=0.01), col = navy) 
  # +
  # coord_cartesian(ylim = c(-2,2), xlim = c(-2,2))
  
} 

# define plotting function for upper diagonale
diagfun <- function(data,mapping){
  
  ggplot(data = data, mapping = mapping)+
    geom_histogram(stat = "count", binwidth = 1, fill = coral) 
  # + 
  #   coord_cartesian(ylim = c(0,100), xlim = c(-2,2))
} 

# create plot
plt <- ggpairs(desc[, -1], lower = list(continuous = wrap(lowerfun)), diag = list(continuous =  wrap(diagfun))) + theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), strip.text.y.right = element_text(angle = 360), strip.text.x.top = element_text(angle = 90))



# plotly::ggplotly(plt)
# print plot
print(suppressWarnings(plt))

```

Based on the scatterplot matrix above, it is possible that correlations are influenced by outliers on the FOS. Below, the same scatterplot matrix is produced after removing the outliers. Indeed, FO is correlated with neighbouring constructs related to attitudes towards learning.  




```{r, echo=FALSE, results='asis', fig.align='center', fig.height=12, fig.width=12, message=F, warning=F}



tmp <- df[, grepl("_outlier", names(df))]


# remove outlier
df$fo_outlier <- is_outlier_iqr(df$fo)
desc <- df[!df$fo_outlier, c("pseudonym", scales)]

# redo scatterplot matrix
# create plot
plt <- ggpairs(desc[, -1], lower = list(continuous = wrap(lowerfun)), diag = list(continuous =  wrap(diagfun))) + theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), strip.text.y.right = element_text(angle = 360), strip.text.x.top = element_text(angle = 90))
print(suppressWarnings(plt))

```

However, as expected, the removal of the outliers also decreases the standard deviation found in the FOS.

```{r, echo = F}

# compute descriptives for fo subscales
tmp <- psych::describe(desc[, grep("fo", names(desc))])
# round values
tmp <- round(tmp, 2)
# add scale name
tmp$vars <- row.names(tmp)

# print to markdown
kbl(tmp, caption = "FOS descriptives (no outlier)", row.names = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```
### n-back data



```{r nback, echo = F, results='asis'}
nback <- names(df)[grep("total_|rate_", names(df))]

# compute descriptives for fo subscales
tmp <- psych::describe(df[, nback])
# round values
tmp <- round(tmp, 2)
# add scale name
tmp$vars <- row.names(tmp)

# print to markdown
kbl(tmp, caption = "n-back descriptives", row.names = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```



```{r, echo=FALSE, results='asis', fig.align='center', fig.height=12, fig.width=12, message=F, warning=F}

# remove outlier
desc <- df[, c("pseudonym", nback)]

# redo scatterplot matrix
# create plot
plt <- ggpairs(desc[, -1], lower = list(continuous = wrap(lowerfun)), diag = list(continuous =  wrap(diagfun))) + theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), strip.text.y.right = element_text(angle = 360), strip.text.x.top = element_text(angle = 90))

print(suppressWarnings(plt))

```




Based on the scatterplot matrix above, participants were removed if their data suggested that they did not understand the task correctly. This was assumed if participants had a response rate (any key press) equal to 1 (n = 1) or equal to 0 (n = 5), if their hit rate was 0 (n = 7) or if the hit rate was smaller than the false alarm rate (n = 3). In total, 9 participants were removed based on these criteria.


```{r, echo=FALSE, results='asis', fig.align='center', fig.height=12, fig.width=12, message=F, warning=F}
rates_nback <- names(df)[grep("rate_", names(df))]


# remove ppt that did not respond at all or responded in all trials or have a hitrate of 0
desc <- df[df$rate_response != 0 & df$rate_response != 1 & df$rate_hits != 0 & df$rate_hits > df$rate_fa, c("pseudonym", rates_nback)]

# compute descriptives for fo subscales
tmp <- psych::describe(desc)
# round values
tmp <- round(tmp, 2)
# add scale name
tmp$vars <- row.names(tmp)

# print to markdown
kbl(tmp, caption = "n-back descriptives", row.names = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

# redo scatterplot matrix
# create plot
plt <- ggpairs(desc[-1], lower = list(continuous = wrap(lowerfun)), diag = list(continuous =  wrap(diagfun))) + theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), strip.text.y.right = element_text(angle = 360), strip.text.x.top = element_text(angle = 90))


plotly::ggplotly(plt)


```

